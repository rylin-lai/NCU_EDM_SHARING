{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLSH æ¸¬è©¦å·¥ä½œåŠ / TLSH Testing Workshop\n",
    "\n",
    "é€™å€‹ notebook å±•ç¤ºå¦‚ä½•ä½¿ç”¨æˆ‘å€‘çš„ TLSH åˆ†æå·¥å…·é€²è¡Œå…©ç¨®ä¸åŒçš„æ¸¬è©¦æ¡ˆä¾‹  \n",
    "This notebook demonstrates how to use our TLSH analysis tool for two different test cases\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™ / Learning Objectives:\n",
    "1. **ä¼æ¥­æ‡‰ç”¨æ¸¬è©¦** / **Enterprise Application Testing**: ä½¿ç”¨ TLSH é€²è¡Œè³‡æ–™å¤–æ´©æª¢æ¸¬ / Use TLSH for data leak detection\n",
    "2. **å¤§è¦æ¨¡è³‡æ–™åˆ†ç¾¤** / **Large-scale Data Clustering**: å°æƒ¡æ„è»Ÿé«”è³‡æ–™é›†é€²è¡Œåˆ†ç¾¤åˆ†æ / Cluster analysis on malware datasets\n",
    "3. **Python å·¥å…·æ•´åˆ** / **Python Tool Integration**: çµåˆ Python è…³æœ¬èˆ‡ pytest æ¸¬è©¦ / Integrate Python scripts with pytest testing\n",
    "4. **è·¨èªè¨€é©—è­‰** / **Cross-language Validation**: æ¯”è¼ƒ Python èˆ‡ Golang å¯¦ä½œçµæœ / Compare Python and Golang implementation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç’°å¢ƒè¨­ç½® / Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°å…¥å¿…è¦çš„å‡½å¼åº« / Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘ / Add current directory to path\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "try:\n",
    "    from tlsh_analyzer import TLSHAnalyzer\n",
    "    print(\"âœ… æˆåŠŸå°å…¥ TLSH åˆ†æå™¨ / Successfully imported TLSH Analyzer\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å°å…¥éŒ¯èª¤ / Import error: {e}\")\n",
    "    print(\"è«‹ç¢ºä¿ tlsh_analyzer.py å­˜åœ¨æ–¼ç•¶å‰ç›®éŒ„ / Please ensure tlsh_analyzer.py exists in current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¡ˆä¾‹ 1: ä¼æ¥­è³‡æ–™å¤–æ´©æª¢æ¸¬ / Case 1: Enterprise Data Leak Detection\n",
    "\n",
    "æ¨¡æ“¬ä¼æ¥­ç’°å¢ƒä¸­çš„è³‡æ–™å¤–æ´©æª¢æ¸¬æƒ…å¢ƒ  \n",
    "Simulate data leak detection scenarios in enterprise environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹æ¸¬è©¦æƒ…å¢ƒ / Create test scenarios\n",
    "analyzer = TLSHAnalyzer()\n",
    "analyzer.verbose = True\n",
    "\n",
    "print(\"ğŸ¢ ä¼æ¥­è³‡æ–™å¤–æ´©æª¢æ¸¬æ¸¬è©¦ / Enterprise Data Leak Detection Test\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# æƒ…å¢ƒ 1: ç”Ÿç”¢ä¼ºæœå™¨ä¸Šçš„å®¢æˆ¶è³‡æ–™ / Scenario 1: Customer data on production server\n",
    "production_data = '''\n",
    "{\n",
    "    \"customer_database\": {\n",
    "        \"customers\": [\n",
    "            {\n",
    "                \"id\": \"CUST_001\",\n",
    "                \"name\": \"ç‹å°æ˜\",\n",
    "                \"email\": \"wang.xiaoming@company.com\",\n",
    "                \"phone\": \"+886-2-1234-5678\",\n",
    "                \"address\": \"å°åŒ—å¸‚ä¿¡ç¾©å€ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ101å¤§æ¨“32F\",\n",
    "                \"credit_card\": \"**** **** **** 1234\",\n",
    "                \"purchase_history\": [\n",
    "                    {\"date\": \"2024-01-15\", \"amount\": 15000, \"product\": \"ä¼æ¥­è»Ÿé«”æˆæ¬Š\"}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"CUST_002\",\n",
    "                \"name\": \"æç¾è¯\",\n",
    "                \"email\": \"li.meihua@company.com\",\n",
    "                \"phone\": \"+886-2-8765-4321\",\n",
    "                \"address\": \"æ–°åŒ—å¸‚æ¿æ©‹å€ä¸­å±±è·¯ä¸€æ®µ161è™Ÿ\",\n",
    "                \"credit_card\": \"**** **** **** 5678\",\n",
    "                \"purchase_history\": [\n",
    "                    {\"date\": \"2024-02-10\", \"amount\": 8500, \"product\": \"æŠ€è¡“æ”¯æ´åŒ…\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "''' * 2  # é‡è¤‡å…§å®¹ä»¥æ»¿è¶³ TLSH æœ€å°é•·åº¦è¦æ±‚ / Repeat content to meet TLSH minimum length requirement\n",
    "\n",
    "# æƒ…å¢ƒ 2: æ¸¬è©¦ä¼ºæœå™¨ä¸Šç™¼ç¾çš„å¯ç–‘è³‡æ–™ / Scenario 2: Suspicious data found on test server\n",
    "test_server_data = '''\n",
    "{\n",
    "    \"customer_database\": {\n",
    "        \"customers\": [\n",
    "            {\n",
    "                \"id\": \"CUST_001\",\n",
    "                \"name\": \"ç‹å°æ˜\",\n",
    "                \"email\": \"wang.xiaoming@company.com\",\n",
    "                \"phone\": \"+886-2-1234-5678\",\n",
    "                \"address\": \"å°åŒ—å¸‚ä¿¡ç¾©å€ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ101å¤§æ¨“32F\",\n",
    "                \"credit_card\": \"**** **** **** 1234\",\n",
    "                \"purchase_history\": [\n",
    "                    {\"date\": \"2024-01-15\", \"amount\": 15000, \"product\": \"ä¼æ¥­è»Ÿé«”æˆæ¬Š\"}\n",
    "                ],\n",
    "                \"last_access\": \"2024-03-15T10:30:00Z\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": \"CUST_002\",\n",
    "                \"name\": \"æç¾è¯\",\n",
    "                \"email\": \"li.meihua@company.com\",\n",
    "                \"phone\": \"+886-2-8765-4321\",\n",
    "                \"address\": \"æ–°åŒ—å¸‚æ¿æ©‹å€ä¸­å±±è·¯ä¸€æ®µ161è™Ÿ\",\n",
    "                \"credit_card\": \"**** **** **** 5678\",\n",
    "                \"purchase_history\": [\n",
    "                    {\"date\": \"2024-02-10\", \"amount\": 8500, \"product\": \"æŠ€è¡“æ”¯æ´åŒ…\"}\n",
    "                ],\n",
    "                \"last_access\": \"2024-03-16T09:15:00Z\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "''' * 2\n",
    "\n",
    "# åŸ·è¡Œæ¯”è¼ƒ / Execute comparison\n",
    "result1 = analyzer.compare_two_texts(production_data, test_server_data)\n",
    "print(f\"\\nğŸ“Š æª¢æ¸¬çµæœ / Detection Results:\")\n",
    "print(f\"è·é›¢ / Distance: {result1['distance']}\")\n",
    "print(f\"åˆ†é¡ / Classification: {result1['similarity_class']}\")\n",
    "print(f\"é¢¨éšªç­‰ç´š / Risk Level: {result1['risk_level']}\")\n",
    "print(f\"\\nè§£é‡‹ / Interpretation:\")\n",
    "print(f\"ä¸­æ–‡: {result1['interpretation']['zh']}\")\n",
    "print(f\"English: {result1['interpretation']['en']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›´å¤šæ¸¬è©¦æ¡ˆä¾‹ / Additional test cases\n",
    "print(\"\\nğŸ” é¡å¤–çš„æª¢æ¸¬æ¡ˆä¾‹ / Additional Detection Cases\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ¡ˆä¾‹ A: æ ¼å¼è½‰æ›å¾Œçš„ç›¸åŒè³‡æ–™ / Case A: Same data after format conversion\n",
    "csv_format_data = '''\n",
    "customer_id,name,email,phone,address,credit_card,last_purchase_amount,last_purchase_product\n",
    "CUST_001,ç‹å°æ˜,wang.xiaoming@company.com,+886-2-1234-5678,\"å°åŒ—å¸‚ä¿¡ç¾©å€ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ101å¤§æ¨“32F\",**** **** **** 1234,15000,ä¼æ¥­è»Ÿé«”æˆæ¬Š\n",
    "CUST_002,æç¾è¯,li.meihua@company.com,+886-2-8765-4321,\"æ–°åŒ—å¸‚æ¿æ©‹å€ä¸­å±±è·¯ä¸€æ®µ161è™Ÿ\",**** **** **** 5678,8500,æŠ€è¡“æ”¯æ´åŒ…\n",
    "''' * 10  # é‡è¤‡ä»¥æ»¿è¶³é•·åº¦è¦æ±‚ / Repeat to meet length requirement\n",
    "\n",
    "result_a = analyzer.compare_two_texts(production_data, csv_format_data)\n",
    "print(f\"\\nğŸ“„ JSON vs CSV æ ¼å¼æ¯”è¼ƒ / JSON vs CSV format comparison:\")\n",
    "print(f\"è·é›¢: {result_a['distance']}, åˆ†é¡: {result_a['similarity_class']}\")\n",
    "\n",
    "# æ¡ˆä¾‹ B: å®Œå…¨ä¸åŒçš„è³‡æ–™ / Case B: Completely different data\n",
    "different_data = '''\n",
    "{\n",
    "    \"employee_database\": {\n",
    "        \"employees\": [\n",
    "            {\n",
    "                \"emp_id\": \"EMP_001\",\n",
    "                \"name\": \"å¼µå·¥ç¨‹å¸«\",\n",
    "                \"department\": \"ç ”ç™¼éƒ¨\",\n",
    "                \"salary\": 80000,\n",
    "                \"skills\": [\"Python\", \"JavaScript\", \"Docker\"]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "''' * 5\n",
    "\n",
    "result_b = analyzer.compare_two_texts(production_data, different_data)\n",
    "print(f\"\\nğŸ‘¥ å®¢æˆ¶è³‡æ–™ vs å“¡å·¥è³‡æ–™æ¯”è¼ƒ / Customer vs Employee data comparison:\")\n",
    "print(f\"è·é›¢: {result_b['distance']}, åˆ†é¡: {result_b['similarity_class']}\")\n",
    "\n",
    "# è¦–è¦ºåŒ–çµæœ / Visualize results\n",
    "distances = [result1['distance'], result_a['distance'], result_b['distance']]\n",
    "labels = ['æ¸¬è©¦ä¼ºæœå™¨\\nTest Server', 'CSVæ ¼å¼\\nCSV Format', 'å“¡å·¥è³‡æ–™\\nEmployee Data']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(labels, distances, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "plt.ylabel('TLSH è·é›¢ / TLSH Distance')\n",
    "plt.title('ä¼æ¥­è³‡æ–™å¤–æ´©æª¢æ¸¬çµæœ / Enterprise Data Leak Detection Results')\n",
    "plt.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='é«˜é¢¨éšªé–¾å€¼ / High Risk Threshold')\n",
    "plt.axhline(y=100, color='orange', linestyle='--', alpha=0.5, label='ä¸­é¢¨éšªé–¾å€¼ / Medium Risk Threshold')\n",
    "\n",
    "# åœ¨æŸ±ç‹€åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼ / Display values on bars\n",
    "for bar, distance in zip(bars, distances):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "             str(distance), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ çµè«– / Conclusions:\")\n",
    "print(f\"â€¢ æ¸¬è©¦ä¼ºæœå™¨è³‡æ–™: è·é›¢ {result1['distance']} - å¯èƒ½æ˜¯è³‡æ–™å¤–æ´©\")\n",
    "print(f\"â€¢ Test server data: Distance {result1['distance']} - Possible data leak\")\n",
    "print(f\"â€¢ CSVæ ¼å¼è³‡æ–™: è·é›¢ {result_a['distance']} - ç›¸åŒè³‡æ–™ä¸åŒæ ¼å¼\")\n",
    "print(f\"â€¢ CSV format data: Distance {result_a['distance']} - Same data different format\")\n",
    "print(f\"â€¢ å“¡å·¥è³‡æ–™: è·é›¢ {result_b['distance']} - å®Œå…¨ä¸åŒçš„è³‡æ–™\")\n",
    "print(f\"â€¢ Employee data: Distance {result_b['distance']} - Completely different data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¡ˆä¾‹ 2: å¤§è¦æ¨¡è³‡æ–™é›†åˆ†ç¾¤åˆ†æ / Case 2: Large-scale Dataset Clustering Analysis\n",
    "\n",
    "ä½¿ç”¨çœŸå¯¦çš„æƒ¡æ„è»Ÿé«”è³‡æ–™é›†é€²è¡Œ DBSCAN åˆ†ç¾¤  \n",
    "Use real malware dataset for DBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”¬ å¤§è¦æ¨¡è³‡æ–™é›†åˆ†ç¾¤åˆ†æ / Large-scale Dataset Clustering Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# æª¢æŸ¥è³‡æ–™é›†æ˜¯å¦å­˜åœ¨ / Check if dataset exists\n",
    "dataset_path = \"./data/mb_1K.csv\"\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"âœ… æ‰¾åˆ°è³‡æ–™é›† / Found dataset: {dataset_path}\")\n",
    "    \n",
    "    # åŸ·è¡Œåˆ†ç¾¤åˆ†æ / Execute clustering analysis\n",
    "    result2 = analyzer.analyze_file_dataset(dataset_path, eps=30, min_samples=2)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š åˆ†ç¾¤çµæœæ‘˜è¦ / Clustering Results Summary:\")\n",
    "    print(f\"ç¸½æ¨£æœ¬æ•¸ / Total samples: {result2['total_samples']}\")\n",
    "    print(f\"æ‰¾åˆ°çš„ç¾¤é›†æ•¸ / Clusters found: {result2['results']['n_clusters']}\")\n",
    "    print(f\"é›œè¨Šé»æ•¸ / Noise points: {result2['results']['n_noise']}\")\n",
    "    print(f\"åˆ†ç¾¤æ•ˆç‡ / Clustering efficiency: {result2['results']['clustering_efficiency']}%\")\n",
    "    \n",
    "    if result2['family_info']['has_family_labels']:\n",
    "        print(f\"å”¯ä¸€å®¶æ—æ•¸ / Unique families: {result2['family_info']['unique_families']}\")\n",
    "    \n",
    "    print(f\"\\næ‘˜è¦ / Summary:\")\n",
    "    print(f\"ä¸­æ–‡: {result2['summary']['zh']}\")\n",
    "    print(f\"English: {result2['summary']['en']}\")\n",
    "    \n",
    "    # æ¸¬è©¦ä¸åŒçš„åƒæ•¸è¨­å®š / Test different parameter settings\n",
    "    print(f\"\\nğŸ”§ åƒæ•¸èª¿æ•´æ¸¬è©¦ / Parameter Tuning Tests:\")\n",
    "    \n",
    "    eps_values = [20, 30, 40, 50]\n",
    "    results_comparison = []\n",
    "    \n",
    "    for eps in eps_values:\n",
    "        try:\n",
    "            temp_result = analyzer.analyze_file_dataset(dataset_path, eps=eps, min_samples=2)\n",
    "            results_comparison.append({\n",
    "                'eps': eps,\n",
    "                'clusters': temp_result['results']['n_clusters'],\n",
    "                'noise': temp_result['results']['n_noise'],\n",
    "                'efficiency': temp_result['results']['clustering_efficiency']\n",
    "            })\n",
    "            print(f\"eps={eps}: {temp_result['results']['n_clusters']} ç¾¤é›†, {temp_result['results']['n_noise']} é›œè¨Šé»\")\n",
    "        except Exception as e:\n",
    "            print(f\"eps={eps}: éŒ¯èª¤ / Error - {e}\")\n",
    "    \n",
    "    # è¦–è¦ºåŒ–åƒæ•¸æ¯”è¼ƒ / Visualize parameter comparison\n",
    "    if results_comparison:\n",
    "        df_comparison = pd.DataFrame(results_comparison)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # ç¾¤é›†æ•¸é‡æ¯”è¼ƒ / Clusters comparison\n",
    "        ax1.plot(df_comparison['eps'], df_comparison['clusters'], 'bo-', linewidth=2, markersize=8)\n",
    "        ax1.set_xlabel('eps åƒæ•¸å€¼ / eps parameter value')\n",
    "        ax1.set_ylabel('ç¾¤é›†æ•¸é‡ / Number of clusters')\n",
    "        ax1.set_title('eps åƒæ•¸å°ç¾¤é›†æ•¸é‡çš„å½±éŸ¿\\nEffect of eps parameter on cluster count')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # åˆ†ç¾¤æ•ˆç‡æ¯”è¼ƒ / Efficiency comparison\n",
    "        ax2.bar(df_comparison['eps'].astype(str), df_comparison['efficiency'], \n",
    "                color='skyblue', alpha=0.7)\n",
    "        ax2.set_xlabel('eps åƒæ•¸å€¼ / eps parameter value')\n",
    "        ax2.set_ylabel('åˆ†ç¾¤æ•ˆç‡ (%) / Clustering efficiency (%)')\n",
    "        ax2.set_title('eps åƒæ•¸å°åˆ†ç¾¤æ•ˆç‡çš„å½±éŸ¿\\nEffect of eps parameter on clustering efficiency')\n",
    "        \n",
    "        # åœ¨æŸ±ç‹€åœ–ä¸Šé¡¯ç¤ºæ•¸å€¼ / Display values on bars\n",
    "        for i, v in enumerate(df_comparison['efficiency']):\n",
    "            ax2.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ æœ€ä½³åƒæ•¸å»ºè­° / Optimal Parameter Recommendations:\")\n",
    "        best_efficiency = df_comparison.loc[df_comparison['efficiency'].idxmax()]\n",
    "        print(f\"æœ€é«˜æ•ˆç‡: eps={best_efficiency['eps']}, æ•ˆç‡={best_efficiency['efficiency']:.1f}%\")\n",
    "        print(f\"Highest efficiency: eps={best_efficiency['eps']}, efficiency={best_efficiency['efficiency']:.1f}%\")\n",
    "\nelse:\n",
    "    print(f\"âŒ æ‰¾ä¸åˆ°è³‡æ–™é›† / Dataset not found: {dataset_path}\")\n",
    "    print(f\"è«‹ç¢ºä¿è³‡æ–™æª”æ¡ˆå­˜åœ¨ / Please ensure data file exists\")\n",
    "    \n",
    "    # ä½¿ç”¨ç¯„ä¾‹åŠŸèƒ½ / Use example function\n",
    "    print(f\"\\nğŸ”„ ä½¿ç”¨å…§å»ºç¯„ä¾‹ / Using built-in example:\")\n",
    "    example_result = analyzer.run_case_2_example()\n",
    "    print(json.dumps(example_result, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python å·¥å…·æ¸¬è©¦ / Python Tool Testing\n",
    "\n",
    "ä½¿ç”¨ pytest æ¸¬è©¦æˆ‘å€‘çš„ TLSH åˆ†æå·¥å…·  \n",
    "Use pytest to test our TLSH analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª åŸ·è¡Œ pytest æ¸¬è©¦ / Running pytest Tests\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æª¢æŸ¥æ¸¬è©¦æª”æ¡ˆæ˜¯å¦å­˜åœ¨ / Check if test file exists\n",
    "test_file = \"test_tlsh_analyzer.py\"\n",
    "if os.path.exists(test_file):\n",
    "    print(f\"âœ… æ‰¾åˆ°æ¸¬è©¦æª”æ¡ˆ / Found test file: {test_file}\")\n",
    "    \n",
    "    # åŸ·è¡Œ pytest / Run pytest\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"python\", \"-m\", \"pytest\", test_file, \"-v\", \"--tb=short\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=60  # 60ç§’è¶…æ™‚ / 60 second timeout\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nğŸ“Š æ¸¬è©¦çµæœ / Test Results:\")\n",
    "        print(f\"è¿”å›ç¢¼ / Return code: {result.returncode}\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(f\"\\næ¨™æº–è¼¸å‡º / Standard Output:\")\n",
    "            print(result.stdout)\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(f\"\\néŒ¯èª¤è¼¸å‡º / Error Output:\")\n",
    "            print(result.stderr)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"\\nâœ… æ‰€æœ‰æ¸¬è©¦é€šé / All tests passed!\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ éƒ¨åˆ†æ¸¬è©¦å¤±æ•— / Some tests failed\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"â±ï¸ æ¸¬è©¦è¶…æ™‚ / Test timeout after 60 seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŸ·è¡Œæ¸¬è©¦æ™‚ç™¼ç”ŸéŒ¯èª¤ / Error running tests: {e}\")\n",
    "        \n",
    "        # æ‰‹å‹•åŸ·è¡Œéƒ¨åˆ†æ¸¬è©¦ / Manually run some tests\n",
    "        print(f\"\\nğŸ”„ æ‰‹å‹•åŸ·è¡ŒåŸºæœ¬æ¸¬è©¦ / Manually running basic tests:\")\n",
    "        \n",
    "        # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½ / Test basic functionality\n",
    "        try:\n",
    "            test_analyzer = TLSHAnalyzer()\n",
    "            test_text1 = \"é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡å­—ï¼Œç”¨æ–¼é©—è­‰ TLSH åŠŸèƒ½æ˜¯å¦æ­£å¸¸é‹ä½œã€‚\" * 3\n",
    "            test_text2 = \"é€™æ˜¯ä¸€å€‹æ¸¬è©¦æ–‡å­—ï¼Œç”¨æ–¼é©—è­‰ TLSH åŠŸèƒ½æ˜¯å¦æ­£å¸¸é‹ä½œï¼\" * 3\n",
    "            \n",
    "            test_result = test_analyzer.compare_two_texts(test_text1, test_text2)\n",
    "            print(f\"âœ… åŸºæœ¬æ–‡å­—æ¯”è¼ƒæ¸¬è©¦é€šé / Basic text comparison test passed\")\n",
    "            print(f\"   è·é›¢ / Distance: {test_result['distance']}\")\n",
    "            \n",
    "        except Exception as test_error:\n",
    "            print(f\"âŒ åŸºæœ¬æ¸¬è©¦å¤±æ•— / Basic test failed: {test_error}\")\n",
    "\nelse:\n",
    "    print(f\"âŒ æ‰¾ä¸åˆ°æ¸¬è©¦æª”æ¡ˆ / Test file not found: {test_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŒ‡ä»¤åˆ—å·¥å…·ç¤ºç¯„ / Command Line Tool Demonstration\n",
    "\n",
    "å±•ç¤ºå¦‚ä½•ä½¿ç”¨ tlsh_analyzer.py ä½œç‚ºæŒ‡ä»¤åˆ—å·¥å…·  \n",
    "Demonstrate how to use tlsh_analyzer.py as a command line tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ’» æŒ‡ä»¤åˆ—å·¥å…·ç¤ºç¯„ / Command Line Tool Demonstration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# æª¢æŸ¥ä¸»è¦è…³æœ¬æ˜¯å¦å­˜åœ¨ / Check if main script exists\n",
    "script_file = \"tlsh_analyzer.py\"\n",
    "if os.path.exists(script_file):\n",
    "    print(f\"âœ… æ‰¾åˆ°ä¸»è¦è…³æœ¬ / Found main script: {script_file}\")\n",
    "    \n",
    "    # ç¤ºç¯„ä¸åŒçš„æŒ‡ä»¤åˆ—ç”¨æ³• / Demonstrate different command line usages\n",
    "    commands = [\n",
    "        {\n",
    "            \"name\": \"æ¡ˆä¾‹ 1 ç¯„ä¾‹ / Case 1 Example\",\n",
    "            \"cmd\": [\"python\", script_file, \"case1\", \"--example\", \"--verbose\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"æ¡ˆä¾‹ 2 ç¯„ä¾‹ / Case 2 Example\", \n",
    "            \"cmd\": [\"python\", script_file, \"case2\", \"--example\", \"--verbose\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"èªªæ˜æ–‡ä»¶ / Help Documentation\",\n",
    "            \"cmd\": [\"python\", script_file, \"--help\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, command_info in enumerate(commands, 1):\n",
    "        print(f\"\\nğŸ”§ ç¤ºç¯„ {i}: {command_info['name']}\")\n",
    "        print(f\"æŒ‡ä»¤ / Command: {' '.join(command_info['cmd'])}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                command_info['cmd'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"âœ… åŸ·è¡ŒæˆåŠŸ / Execution successful\")\n",
    "                if result.stdout:\n",
    "                    # é™åˆ¶è¼¸å‡ºé•·åº¦ / Limit output length\n",
    "                    output = result.stdout\n",
    "                    if len(output) > 1000:\n",
    "                        output = output[:1000] + \"\\n...ï¼ˆè¼¸å‡ºå·²æˆªæ–· / Output truncatedï¼‰\"\n",
    "                    print(output)\n",
    "            else:\n",
    "                print(f\"âŒ åŸ·è¡Œå¤±æ•— / Execution failed (è¿”å›ç¢¼ / Return code: {result.returncode})\")\n",
    "                if result.stderr:\n",
    "                    print(f\"éŒ¯èª¤ / Error: {result.stderr[:500]}\")\n",
    "                    \n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(f\"â±ï¸ æŒ‡ä»¤è¶…æ™‚ / Command timeout\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åŸ·è¡ŒéŒ¯èª¤ / Execution error: {e}\")\n",
    "\nelse:\n",
    "    print(f\"âŒ æ‰¾ä¸åˆ°ä¸»è¦è…³æœ¬ / Main script not found: {script_file}\")\n",
    "\n",
    "print(f\"\\nğŸ“š ä½¿ç”¨æŒ‡å— / Usage Guide:\")\n",
    "print(f\"1. åŸºæœ¬æ–‡å­—æ¯”è¼ƒ / Basic text comparison:\")\n",
    "print(f\"   python tlsh_analyzer.py case1 --text1 'æ–‡å­—1' --text2 'æ–‡å­—2'\")\n",
    "print(f\"\\n2. è³‡æ–™é›†åˆ†ç¾¤åˆ†æ / Dataset clustering analysis:\")\n",
    "print(f\"   python tlsh_analyzer.py case2 --csv data/mb_1K.csv\")\n",
    "print(f\"\\n3. è‡ªè¨‚åƒæ•¸ / Custom parameters:\")\n",
    "print(f\"   python tlsh_analyzer.py case2 --csv data.csv --eps 25 --min_samples 3\")\n",
    "print(f\"\\n4. ä¿å­˜çµæœ / Save results:\")\n",
    "print(f\"   python tlsh_analyzer.py case1 --example --output results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¸½çµå’Œä¸‹ä¸€æ­¥ / Summary and Next Steps\n",
    "\n",
    "é€™å€‹å·¥ä½œåŠå±•ç¤ºäº†ï¼š  \n",
    "This workshop demonstrated:\n",
    "\n",
    "### å·²å®Œæˆçš„åŠŸèƒ½ / Completed Features:\n",
    "âœ… **Python TLSH åˆ†æå™¨** / **Python TLSH Analyzer**  \n",
    "âœ… **ä¼æ¥­è³‡æ–™å¤–æ´©æª¢æ¸¬** / **Enterprise Data Leak Detection**  \n",
    "âœ… **å¤§è¦æ¨¡è³‡æ–™é›†åˆ†ç¾¤** / **Large-scale Dataset Clustering**  \n",
    "âœ… **pytest æ¸¬è©¦å¥—ä»¶** / **pytest Test Suite**  \n",
    "âœ… **æŒ‡ä»¤åˆ—ä»‹é¢** / **Command Line Interface**  \n",
    "\n",
    "### ä¸‹ä¸€æ­¥ / Next Steps:\n",
    "ğŸ”„ **Golang ç‰ˆæœ¬å¯¦ä½œ** / **Golang Version Implementation**  \n",
    "ğŸ”„ **è·¨èªè¨€çµæœé©—è­‰** / **Cross-language Result Validation**  \n",
    "ğŸ”„ **æ•ˆèƒ½åŸºæº–æ¸¬è©¦** / **Performance Benchmarking**  \n",
    "ğŸ”„ **æ•´åˆ CI/CD æµç¨‹** / **CI/CD Pipeline Integration**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ TLSH æ¸¬è©¦å·¥ä½œåŠå®Œæˆï¼/ TLSH Testing Workshop Completed!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ç¸½çµçµ±è¨ˆ / Summary statistics\n",
    "print(f\"ğŸ“Š å·¥ä½œåŠçµ±è¨ˆ / Workshop Statistics:\")\n",
    "print(f\"â€¢ æ¸¬è©¦æ¡ˆä¾‹æ•¸ / Test cases: 2 (ä¼æ¥­æª¢æ¸¬ + è³‡æ–™åˆ†ç¾¤ / Enterprise detection + Data clustering)\")\n",
    "print(f\"â€¢ Python æª”æ¡ˆ / Python files: 2 (tlsh_analyzer.py + test_tlsh_analyzer.py)\")\n",
    "print(f\"â€¢ æ”¯æ´çš„è¼¸å…¥æ ¼å¼ / Supported input formats: JSON, CSV, ç´”æ–‡å­— / Plain text\")\n",
    "print(f\"â€¢ æ”¯æ´çš„è¼¸å‡ºæ ¼å¼ / Supported output formats: JSON, æ§åˆ¶å° / Console\")\n",
    "\n",
    "print(f\"\\nğŸš€ å»ºè­°çš„ä¸‹ä¸€æ­¥è¡Œå‹• / Suggested Next Actions:\")\n",
    "print(f\"1. å¯¦ä½œ Golang ç‰ˆæœ¬ä¾†æ¯”è¼ƒæ•ˆèƒ½ / Implement Golang version for performance comparison\")\n",
    "print(f\"2. å»ºç«‹è‡ªå‹•åŒ–æ¸¬è©¦æµç¨‹ / Set up automated testing pipeline\")\n",
    "print(f\"3. æ•´åˆåˆ°ä¼æ¥­å®‰å…¨ç›£æ§ç³»çµ± / Integrate into enterprise security monitoring system\")\n",
    "print(f\"4. æ“´å±•åˆ°æ›´å¤šæª”æ¡ˆæ ¼å¼æ”¯æ´ / Extend to support more file formats\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ å­¸ç¿’é‡é» / Key Learning Points:\")\n",
    "print(f\"â€¢ TLSH é©åˆæª¢æ¸¬è³‡æ–™ç›¸ä¼¼æ€§è€Œéç²¾ç¢ºåŒ¹é… / TLSH is suitable for detecting data similarity, not exact matching\")\n",
    "print(f\"â€¢ DBSCAN åƒæ•¸èª¿æ•´å°åˆ†ç¾¤çµæœæœ‰é‡è¦å½±éŸ¿ / DBSCAN parameter tuning significantly affects clustering results\")\n",
    "print(f\"â€¢ pytest æä¾›å®Œæ•´çš„æ¸¬è©¦è¦†è“‹å’Œé©—è­‰ / pytest provides comprehensive testing coverage and validation\")\n",
    "print(f\"â€¢ æŒ‡ä»¤åˆ—å·¥å…·å¢åŠ äº†å¯¦ç”¨æ€§å’Œæ•´åˆèƒ½åŠ› / Command line tool enhances practicality and integration capability\")\n",
    "\n",
    "print(f\"\\nğŸ¯ å¯¦éš›æ‡‰ç”¨å ´æ™¯ / Real-world Application Scenarios:\")\n",
    "print(f\"â€¢ è³‡å®‰äº‹ä»¶èª¿æŸ¥ / Security incident investigation\")\n",
    "print(f\"â€¢ è³‡æ–™å¤–æ´©æª¢æ¸¬ / Data leak detection\")\n",
    "print(f\"â€¢ æƒ¡æ„è»Ÿé«”å®¶æ—åˆ†é¡ / Malware family classification\")\n",
    "print(f\"â€¢ è³‡æ–™è­œç³»è¿½è¹¤ / Data lineage tracking\")\n",
    "print(f\"â€¢ åˆè¦æ€§å¯©è¨ˆæ”¯æ´ / Compliance audit support\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
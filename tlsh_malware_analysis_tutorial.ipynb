{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header-cell",
      "metadata": {},
      "source": [
        "# TLSH Malware Analysis Tutorial / TLSH æƒ¡æ„è»Ÿé«”åˆ†ææ•™å­¸\n",
        "\n",
        "## Real-world Malware Classification with TLSH / ä½¿ç”¨ TLSH é€²è¡ŒçœŸå¯¦æƒ¡æ„è»Ÿé«”åˆ†é¡\n",
        "\n",
        "**Instructor / è¬›å¸«:** Rylin Lai (è³´ç‘éœ–)  \n",
        "**Position / è·ä½:** Software Engineer, Trend Micro â€“ Commercial Endpoint\n",
        "\n",
        "---\n",
        "\n",
        "### Tutorial Overview / æ•™å­¸æ¦‚è¿°:\n",
        "This tutorial demonstrates practical malware analysis using TLSH with real-world malware samples. We'll analyze raw malware data, perform clustering, and interpret the results for threat intelligence.\n",
        "\n",
        "æœ¬æ•™å­¸ä½¿ç”¨çœŸå¯¦ä¸–ç•Œçš„æƒ¡æ„è»Ÿé«”æ¨£æœ¬ç¤ºç¯„ä½¿ç”¨ TLSH é€²è¡Œå¯¦ç”¨çš„æƒ¡æ„è»Ÿé«”åˆ†æã€‚æˆ‘å€‘å°‡åˆ†æåŸå§‹æƒ¡æ„è»Ÿé«”è³‡æ–™ã€åŸ·è¡Œåˆ†ç¾¤ä¸¦è§£é‡‹å¨è„…æƒ…å ±çš„çµæœã€‚\n",
        "\n",
        "### Learning Objectives / å­¸ç¿’ç›®æ¨™:\n",
        "1. **Load and explore real malware datasets / è¼‰å…¥å’Œæ¢ç´¢çœŸå¯¦æƒ¡æ„è»Ÿé«”è³‡æ–™é›†**\n",
        "2. **Apply TLSH clustering algorithms (HAC-T, DBSCAN) / æ‡‰ç”¨ TLSH åˆ†ç¾¤æ¼”ç®—æ³•**\n",
        "3. **Classify unknown malware samples / åˆ†é¡æœªçŸ¥æƒ¡æ„è»Ÿé«”æ¨£æœ¬**\n",
        "4. **Interpret clustering results for threat analysis / è§£è®€åˆ†ç¾¤çµæœç”¨æ–¼å¨è„…åˆ†æ**\n",
        "\n",
        "### Dataset Information / è³‡æ–™é›†è³‡è¨Š:\n",
        "- **Source / ä¾†æº**: Real malware samples (sanitized for educational use)\n",
        "- **Format / æ ¼å¼**: `sha1_hash,tlsh,signature`\n",
        "- **Families / å®¶æ—**: Quakbot, TrickBot, Heodo, Mirai, AgentTesla, and more"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-section",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Data Loading / æ­¥é©Ÿ 1ï¼šè¨­ç½®å’Œè³‡æ–™è¼‰å…¥\n",
        "\n",
        "### Understanding Raw Malware Data / äº†è§£åŸå§‹æƒ¡æ„è»Ÿé«”è³‡æ–™\n",
        "\n",
        "Our dataset contains real malware samples with the following format:\n",
        "\n",
        "æˆ‘å€‘çš„è³‡æ–™é›†åŒ…å«çœŸå¯¦çš„æƒ¡æ„è»Ÿé«”æ¨£æœ¬ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n",
        "\n",
        "| Column / æ¬„ä½ | Description / æè¿° |\n",
        "|---------------|--------------------|\n",
        "| **sha1_hash** | SHA1 hash of the malware file / æƒ¡æ„è»Ÿé«”æª”æ¡ˆçš„ SHA1 é›œæ¹Š |\n",
        "| **tlsh** | TLSH similarity hash / TLSH ç›¸ä¼¼æ€§é›œæ¹Š |\n",
        "| **signature** | Known malware family name / å·²çŸ¥æƒ¡æ„è»Ÿé«”å®¶æ—åç¨± |\n",
        "\n",
        "This is **raw malware data**, not pre-clustered results. We will perform the clustering analysis ourselves.\n",
        "\n",
        "é€™æ˜¯**åŸå§‹æƒ¡æ„è»Ÿé«”è³‡æ–™**ï¼Œä¸æ˜¯é å…ˆåˆ†ç¾¤çš„çµæœã€‚æˆ‘å€‘å°‡è‡ªå·±åŸ·è¡Œåˆ†ç¾¤åˆ†æã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries / åŒ¯å…¥å¿…è¦å‡½å¼åº«\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add the clustering library to the path / å°‡åˆ†ç¾¤å‡½å¼åº«åŠ å…¥è·¯å¾‘\n",
        "sys.path.append('../tlshCluster')\n",
        "\n",
        "try:\n",
        "    from pylib.tlsh_lib import *\n",
        "    from pylib.hac_lib import *\n",
        "    print(\"âœ… Successfully imported TLSH clustering libraries\")\n",
        "    print(\"âœ… æˆåŠŸåŒ¯å…¥ TLSH åˆ†ç¾¤å‡½å¼åº«\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Error importing libraries: {e}\")\n",
        "    print(f\"âŒ åŒ¯å…¥å‡½å¼åº«éŒ¯èª¤ï¼š{e}\")\n",
        "    print(\"Please ensure the clustering library is available\")\n",
        "    print(\"è«‹ç¢ºä¿åˆ†ç¾¤å‡½å¼åº«å¯ç”¨\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "load-dataset",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the real malware dataset / è¼‰å…¥çœŸå¯¦æƒ¡æ„è»Ÿé«”è³‡æ–™é›†\n",
        "print(\"ğŸ“Š Loading Real Malware Dataset / è¼‰å…¥çœŸå¯¦æƒ¡æ„è»Ÿé«”è³‡æ–™é›†\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load dataset using pandas for exploration\n",
        "# ä½¿ç”¨ pandas è¼‰å…¥è³‡æ–™é›†ä»¥é€²è¡Œæ¢ç´¢\n",
        "try:\n",
        "    df = pd.read_csv('data/mb_10K.csv')\n",
        "    print(f\"âœ… Dataset loaded successfully: {len(df):,} malware samples\")\n",
        "    print(f\"âœ… è³‡æ–™é›†è¼‰å…¥æˆåŠŸï¼š{len(df):,} å€‹æƒ¡æ„è»Ÿé«”æ¨£æœ¬\")\n",
        "    \n",
        "    print(\"\\nğŸ“‹ Dataset Structure / è³‡æ–™é›†çµæ§‹:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    print(\"\\nğŸ“ˆ Dataset Summary / è³‡æ–™é›†æ‘˜è¦:\")\n",
        "    print(f\"   Total samples / ç¸½æ¨£æœ¬æ•¸: {len(df):,}\")\n",
        "    print(f\"   Unique families / å”¯ä¸€å®¶æ—æ•¸: {df['signature'].nunique():,}\")\n",
        "    print(f\"   Columns / æ¬„ä½: {list(df.columns)}\")\n",
        "    \n",
        "    print(\"\\nğŸ” Data Quality Check / è³‡æ–™å“è³ªæª¢æŸ¥:\")\n",
        "    print(f\"   Valid TLSH hashes / æœ‰æ•ˆ TLSH é›œæ¹Š: {df['tlsh'].notna().sum():,}\")\n",
        "    print(f\"   Valid SHA1 hashes / æœ‰æ•ˆ SHA1 é›œæ¹Š: {df['sha1_hash'].notna().sum():,}\")\n",
        "    print(f\"   Labeled samples / å·²æ¨™è¨˜æ¨£æœ¬: {df['signature'].notna().sum():,}\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ Dataset file not found. Please ensure data/mb_10K.csv exists.\")\n",
        "    print(\"âŒ æ‰¾ä¸åˆ°è³‡æ–™é›†æª”æ¡ˆã€‚è«‹ç¢ºä¿ data/mb_10K.csv å­˜åœ¨ã€‚\")\n",
        "    # Try smaller dataset as fallback\n",
        "    try:\n",
        "        df = pd.read_csv('data/mb_1K.csv')\n",
        "        print(f\"âœ… Using smaller dataset: {len(df):,} samples\")\n",
        "        print(f\"âœ… ä½¿ç”¨è¼ƒå°è³‡æ–™é›†ï¼š{len(df):,} å€‹æ¨£æœ¬\")\n",
        "    except:\n",
        "        print(\"âŒ No dataset files available\")\n",
        "        df = None\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading dataset: {e}\")\n",
        "    df = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "family-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze malware families in the dataset / åˆ†æè³‡æ–™é›†ä¸­çš„æƒ¡æ„è»Ÿé«”å®¶æ—\n",
        "print(\"ğŸ¦  Malware Family Distribution / æƒ¡æ„è»Ÿé«”å®¶æ—åˆ†ä½ˆ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if df is not None and len(df) > 0:\n",
        "    # Count samples by family / æŒ‰å®¶æ—è¨ˆç®—æ¨£æœ¬æ•¸\n",
        "    family_counts = df['signature'].value_counts()\n",
        "    \n",
        "    print(f\"ğŸ“Š Top {min(15, len(family_counts))} Malware Families / å‰ {min(15, len(family_counts))} å¤§æƒ¡æ„è»Ÿé«”å®¶æ—:\")\n",
        "    print(\"\\nFamily Name (å®¶æ—åç¨±)        | Sample Count (æ¨£æœ¬æ•¸)\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for family, count in family_counts.head(15).items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"{family:<25} | {count:>6} ({percentage:5.1f}%)\")\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    family_counts.head(10).plot(kind='bar')\n",
        "    plt.title('Top 10 Malware Families in Dataset\\nè³‡æ–™é›†ä¸­å‰ 10 å¤§æƒ¡æ„è»Ÿé«”å®¶æ—')\n",
        "    plt.xlabel('Malware Family / æƒ¡æ„è»Ÿé«”å®¶æ—')\n",
        "    plt.ylabel('Number of Samples / æ¨£æœ¬æ•¸é‡')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Family Analysis Notes / å®¶æ—åˆ†æèªªæ˜:\")\n",
        "    print(\"â€¢ This shows the distribution of known malware families in our dataset\")\n",
        "    print(\"â€¢ é¡¯ç¤ºæˆ‘å€‘è³‡æ–™é›†ä¸­å·²çŸ¥æƒ¡æ„è»Ÿé«”å®¶æ—çš„åˆ†ä½ˆ\")\n",
        "    print(\"â€¢ We will use these labels to validate our clustering results\")\n",
        "    print(\"â€¢ æˆ‘å€‘å°‡ä½¿ç”¨é€™äº›æ¨™ç±¤ä¾†é©—è­‰æˆ‘å€‘çš„åˆ†ç¾¤çµæœ\")\n",
        "    \n",
        "else:\n",
        "    print(\"âŒ No data available for analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clustering-section",
      "metadata": {},
      "source": [
        "## Step 2: TLSH Distance Analysis / æ­¥é©Ÿ 2ï¼šTLSH è·é›¢åˆ†æ\n",
        "\n",
        "### Understanding TLSH Distance in Malware Analysis / äº†è§£æƒ¡æ„è»Ÿé«”åˆ†æä¸­çš„ TLSH è·é›¢\n",
        "\n",
        "Before clustering, let's understand how TLSH distances work with real malware samples:\n",
        "\n",
        "åœ¨åˆ†ç¾¤ä¹‹å‰ï¼Œè®“æˆ‘å€‘äº†è§£ TLSH è·é›¢å¦‚ä½•èˆ‡çœŸå¯¦æƒ¡æ„è»Ÿé«”æ¨£æœ¬ä¸€èµ·å·¥ä½œï¼š\n",
        "\n",
        "- **Distance = 0**: Identical files / ç›¸åŒæª”æ¡ˆ\n",
        "- **Distance 1-50**: Very similar variants / éå¸¸ç›¸ä¼¼çš„è®Šç¨®\n",
        "- **Distance 51-100**: Same family, different versions / åŒå®¶æ—ï¼Œä¸åŒç‰ˆæœ¬\n",
        "- **Distance > 100**: Different malware families / ä¸åŒæƒ¡æ„è»Ÿé«”å®¶æ—\n",
        "\n",
        "### Distance Calculation Process / è·é›¢è¨ˆç®—æµç¨‹:\n",
        "1. **Load TLSH data** using the clustering library / ä½¿ç”¨åˆ†ç¾¤å‡½å¼åº«è¼‰å…¥ TLSH è³‡æ–™\n",
        "2. **Calculate pairwise distances** between samples / è¨ˆç®—æ¨£æœ¬é–“çš„æˆå°è·é›¢\n",
        "3. **Analyze distance distribution** / åˆ†æè·é›¢åˆ†ä½ˆ\n",
        "4. **Choose clustering parameters** / é¸æ“‡åˆ†ç¾¤åƒæ•¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tlsh-distance-analysis",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data using TLSH library and analyze distances / ä½¿ç”¨ TLSH å‡½å¼åº«è¼‰å…¥è³‡æ–™ä¸¦åˆ†æè·é›¢\n",
        "print(\"ğŸ” TLSH Distance Analysis / TLSH è·é›¢åˆ†æ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    # Load data using TLSH library functions\n",
        "    # ä½¿ç”¨ TLSH å‡½å¼åº«åŠŸèƒ½è¼‰å…¥è³‡æ–™\n",
        "    dataset_file = 'data/mb_10K.csv' if os.path.exists('data/mb_10K.csv') else 'data/mb_1K.csv'\n",
        "    \n",
        "    print(f\"ğŸ“‚ Loading {dataset_file} with TLSH library...\")\n",
        "    (tlist, labels) = tlsh_csvfile(dataset_file)\n",
        "    \n",
        "    if tlist is not None:\n",
        "        print(f\"âœ… Loaded {len(tlist)} TLSH hashes successfully\")\n",
        "        print(f\"âœ… æˆåŠŸè¼‰å…¥ {len(tlist)} å€‹ TLSH é›œæ¹Š\")\n",
        "        \n",
        "        # Analyze a subset of distances for visualization\n",
        "        # åˆ†æè·é›¢å­é›†ä»¥é€²è¡Œè¦–è¦ºåŒ–\n",
        "        sample_size = min(100, len(tlist))  # Use first 100 samples for speed\n",
        "        \n",
        "        print(f\"\\nğŸ“Š Analyzing distances between first {sample_size} samples...\")\n",
        "        print(f\"ğŸ“Š åˆ†æå‰ {sample_size} å€‹æ¨£æœ¬ä¹‹é–“çš„è·é›¢...\")\n",
        "        \n",
        "        # Calculate sample distances\n",
        "        distances = []\n",
        "        for i in range(min(20, sample_size)):\n",
        "            for j in range(i+1, min(i+10, sample_size)):  # Limited comparison for performance\n",
        "                try:\n",
        "                    # Convert TLSH strings to objects and calculate distance\n",
        "                    import tlsh\n",
        "                    h1 = tlsh.Tlsh()\n",
        "                    h1.fromTlshStr(tlist[i])\n",
        "                    h2 = tlsh.Tlsh()\n",
        "                    h2.fromTlshStr(tlist[j])\n",
        "                    dist = h1.diff(h2)\n",
        "                    \n",
        "                    if dist != -1:  # Valid distance\n",
        "                        distances.append(dist)\n",
        "                        \n",
        "                        # Show some example distances with family info\n",
        "                        if len(distances) <= 10:\n",
        "                            family1 = labels[0][i] if labels and len(labels[0]) > i else 'Unknown'\n",
        "                            family2 = labels[0][j] if labels and len(labels[0]) > j else 'Unknown'\n",
        "                            same_family = \"âœ“\" if family1 == family2 else \"âœ—\"\n",
        "                            print(f\"   Sample {i+1:2d} vs {j+1:2d}: distance={dist:3d} | {family1:12} vs {family2:12} | Same: {same_family}\")\n",
        "                            \n",
        "                except Exception as e:\n",
        "                    continue\n",
        "        \n",
        "        if distances:\n",
        "            print(f\"\\nğŸ“ˆ Distance Statistics / è·é›¢çµ±è¨ˆ:\")\n",
        "            print(f\"   Calculated distances / è¨ˆç®—çš„è·é›¢æ•¸: {len(distances)}\")\n",
        "            print(f\"   Min distance / æœ€å°è·é›¢: {min(distances)}\")\n",
        "            print(f\"   Max distance / æœ€å¤§è·é›¢: {max(distances)}\")\n",
        "            print(f\"   Average distance / å¹³å‡è·é›¢: {np.mean(distances):.1f}\")\n",
        "            \n",
        "            # Visualize distance distribution\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plt.hist(distances, bins=20, alpha=0.7, edgecolor='black')\n",
        "            plt.axvline(x=50, color='orange', linestyle='--', label='Family boundary (â‰¤50: variants)')\n",
        "            plt.axvline(x=100, color='red', linestyle='--', label='Family boundary (â‰¤100: same family)')\n",
        "            plt.xlabel('TLSH Distance / TLSH è·é›¢')\n",
        "            plt.ylabel('Frequency / é »ç‡')\n",
        "            plt.title('Distribution of TLSH Distances Between Malware Samples\\næƒ¡æ„è»Ÿé«”æ¨£æœ¬é–“çš„ TLSH è·é›¢åˆ†ä½ˆ')\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.show()\n",
        "            \n",
        "            print(\"\\nğŸ’¡ Distance Analysis Insights / è·é›¢åˆ†ææ´å¯Ÿ:\")\n",
        "            close_samples = sum(1 for d in distances if d <= 50)\n",
        "            same_family_samples = sum(1 for d in distances if 50 < d <= 100)\n",
        "            different_family_samples = sum(1 for d in distances if d > 100)\n",
        "            \n",
        "            print(f\"   â€¢ Very similar samples (â‰¤50): {close_samples} pairs\")\n",
        "            print(f\"   â€¢ Same family samples (51-100): {same_family_samples} pairs\")\n",
        "            print(f\"   â€¢ Different families (>100): {different_family_samples} pairs\")\n",
        "            print(f\"   â€¢ éå¸¸ç›¸ä¼¼æ¨£æœ¬ (â‰¤50)ï¼š{close_samples} å°\")\n",
        "            print(f\"   â€¢ åŒå®¶æ—æ¨£æœ¬ (51-100)ï¼š{same_family_samples} å°\")\n",
        "            print(f\"   â€¢ ä¸åŒå®¶æ— (>100)ï¼š{different_family_samples} å°\")\n",
        "        \n",
        "    else:\n",
        "        print(\"âŒ Failed to load TLSH data\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error in distance analysis: {e}\")\n",
        "    print(\"This may be due to TLSH library compatibility issues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clustering-algorithms-section",
      "metadata": {},
      "source": [
        "## Step 3: Malware Clustering with DBSCAN / æ­¥é©Ÿ 3ï¼šä½¿ç”¨ DBSCAN é€²è¡Œæƒ¡æ„è»Ÿé«”åˆ†ç¾¤\n",
        "\n",
        "### Why DBSCAN for Malware Analysis? / ç‚ºä»€éº¼åœ¨æƒ¡æ„è»Ÿé«”åˆ†æä¸­ä½¿ç”¨ DBSCANï¼Ÿ\n",
        "\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is excellent for malware analysis because:\n",
        "\n",
        "DBSCANï¼ˆåŸºæ–¼å¯†åº¦çš„ç©ºé–“åˆ†ç¾¤æ‡‰ç”¨èˆ‡é›œè¨Šï¼‰åœ¨æƒ¡æ„è»Ÿé«”åˆ†æä¸­è¡¨ç¾å„ªç§€ï¼Œå› ç‚ºï¼š\n",
        "\n",
        "- **Handles noise**: Identifies outlier samples that don't belong to any family\n",
        "- **è™•ç†é›œè¨Š**: è­˜åˆ¥ä¸å±¬æ–¼ä»»ä½•å®¶æ—çš„é›¢ç¾¤æ¨£æœ¬\n",
        "- **No predetermined cluster count**: Automatically determines the number of families\n",
        "- **ç„¡é å®šç¾¤é›†æ•¸**: è‡ªå‹•ç¢ºå®šå®¶æ—æ•¸é‡\n",
        "- **Distance-based**: Works well with TLSH similarity distances\n",
        "- **åŸºæ–¼è·é›¢**: èˆ‡ TLSH ç›¸ä¼¼æ€§è·é›¢é…åˆè‰¯å¥½\n",
        "\n",
        "### DBSCAN Parameters / DBSCAN åƒæ•¸:\n",
        "- **eps**: Maximum distance between samples in the same cluster (typically 30-50 for malware)\n",
        "- **eps**: åŒä¸€ç¾¤é›†ä¸­æ¨£æœ¬é–“çš„æœ€å¤§è·é›¢ï¼ˆæƒ¡æ„è»Ÿé«”é€šå¸¸ç‚º 30-50ï¼‰\n",
        "- **min_samples**: Minimum samples required to form a cluster (typically 2-3)\n",
        "- **min_samples**: å½¢æˆç¾¤é›†æ‰€éœ€çš„æœ€å°æ¨£æœ¬æ•¸ï¼ˆé€šå¸¸ç‚º 2-3ï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbscan-clustering",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply DBSCAN clustering to malware data / å°æƒ¡æ„è»Ÿé«”è³‡æ–™æ‡‰ç”¨ DBSCAN åˆ†ç¾¤\n",
        "print(\"ğŸ¯ DBSCAN Malware Clustering / DBSCAN æƒ¡æ„è»Ÿé«”åˆ†ç¾¤\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    if 'tlist' in locals() and tlist is not None:\n",
        "        # Use a subset for faster processing in demonstration\n",
        "        # åœ¨ç¤ºç¯„ä¸­ä½¿ç”¨å­é›†ä»¥åŠ å¿«è™•ç†é€Ÿåº¦\n",
        "        max_samples = min(500, len(tlist))  # Limit for performance\n",
        "        tlist_subset = tlist[:max_samples]\n",
        "        labels_subset = [labels[0][:max_samples]] if labels else None\n",
        "        \n",
        "        print(f\"ğŸ“Š Clustering {max_samples} samples using DBSCAN...\")\n",
        "        print(f\"ğŸ“Š ä½¿ç”¨ DBSCAN å° {max_samples} å€‹æ¨£æœ¬é€²è¡Œåˆ†ç¾¤...\")\n",
        "        \n",
        "        # Apply DBSCAN with malware-appropriate parameters\n",
        "        # ä½¿ç”¨é©åˆæƒ¡æ„è»Ÿé«”çš„åƒæ•¸æ‡‰ç”¨ DBSCAN\n",
        "        dbscan_result = runDBSCAN(tlist_subset, eps=30, min_samples=2)\n",
        "        \n",
        "        if hasattr(dbscan_result, 'labels_'):\n",
        "            cluster_labels = dbscan_result.labels_\n",
        "            \n",
        "            # Analyze clustering results\n",
        "            # åˆ†æåˆ†ç¾¤çµæœ\n",
        "            unique_labels = set(cluster_labels)\n",
        "            n_clusters = len(unique_labels) - (1 if -1 in cluster_labels else 0)\n",
        "            n_noise = list(cluster_labels).count(-1)\n",
        "            \n",
        "            print(f\"\\nâœ… DBSCAN Clustering Results / DBSCAN åˆ†ç¾¤çµæœ:\")\n",
        "            print(f\"   Clusters formed / å½¢æˆçš„ç¾¤é›†æ•¸: {n_clusters}\")\n",
        "            print(f\"   Noise samples / é›œè¨Šæ¨£æœ¬æ•¸: {n_noise}\")\n",
        "            print(f\"   Clustered samples / å·²åˆ†ç¾¤æ¨£æœ¬æ•¸: {max_samples - n_noise}\")\n",
        "            print(f\"   Clustering rate / åˆ†ç¾¤ç‡: {((max_samples - n_noise) / max_samples * 100):.1f}%\")\n",
        "            \n",
        "            # Analyze cluster quality using known family labels\n",
        "            if labels_subset and labels_subset[0]:\n",
        "                print(f\"\\nğŸ” Cluster Quality Analysis / ç¾¤é›†å“è³ªåˆ†æ:\")\n",
        "                \n",
        "                # Show cluster composition\n",
        "                for cluster_id in sorted(unique_labels):\n",
        "                    if cluster_id == -1:\n",
        "                        continue  # Skip noise for now\n",
        "                    \n",
        "                    cluster_indices = [i for i, label in enumerate(cluster_labels) if label == cluster_id]\n",
        "                    if len(cluster_indices) <= 10:  # Only show small clusters for clarity\n",
        "                        cluster_families = [labels_subset[0][i] for i in cluster_indices]\n",
        "                        family_counts = {}\n",
        "                        for family in cluster_families:\n",
        "                            family_counts[family] = family_counts.get(family, 0) + 1\n",
        "                        \n",
        "                        print(f\"   Cluster {cluster_id}: {len(cluster_indices)} samples\")\n",
        "                        for family, count in sorted(family_counts.items()):\n",
        "                            print(f\"      {family}: {count} samples\")\n",
        "            \n",
        "            # Create visualization\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            \n",
        "            # Plot cluster distribution\n",
        "            plt.subplot(2, 2, 1)\n",
        "            cluster_sizes = [list(cluster_labels).count(label) for label in unique_labels if label != -1]\n",
        "            plt.hist(cluster_sizes, bins=20, alpha=0.7, edgecolor='black')\n",
        "            plt.xlabel('Cluster Size / ç¾¤é›†å¤§å°')\n",
        "            plt.ylabel('Frequency / é »ç‡')\n",
        "            plt.title('Distribution of Cluster Sizes\\nç¾¤é›†å¤§å°åˆ†ä½ˆ')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Plot clustering summary\n",
        "            plt.subplot(2, 2, 2)\n",
        "            categories = ['Clustered\\\\nå·²åˆ†ç¾¤', 'Noise\\\\né›œè¨Š']\n",
        "            values = [max_samples - n_noise, n_noise]\n",
        "            colors = ['lightblue', 'lightcoral']\n",
        "            plt.pie(values, labels=categories, colors=colors, autopct='%1.1f%%')\n",
        "            plt.title('Clustering vs Noise Samples\\nåˆ†ç¾¤ vs é›œè¨Šæ¨£æœ¬')\n",
        "            \n",
        "            # Plot cluster IDs (limited view)\n",
        "            plt.subplot(2, 1, 2)\n",
        "            sample_indices = range(min(100, len(cluster_labels)))\n",
        "            sample_labels = cluster_labels[:len(sample_indices)]\n",
        "            colors = ['red' if x == -1 else plt.cm.tab10(x % 10) for x in sample_labels]\n",
        "            plt.scatter(sample_indices, sample_labels, c=colors, alpha=0.7)\n",
        "            plt.xlabel('Sample Index / æ¨£æœ¬ç´¢å¼•')\n",
        "            plt.ylabel('Cluster ID / ç¾¤é›† ID')\n",
        "            plt.title('Sample Cluster Assignments (First 100 samples)\\næ¨£æœ¬ç¾¤é›†åˆ†é…ï¼ˆå‰ 100 å€‹æ¨£æœ¬ï¼‰')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            print(\"\\nğŸ’¡ DBSCAN Analysis Insights / DBSCAN åˆ†ææ´å¯Ÿ:\")\n",
        "            print(f\"â€¢ DBSCAN effectively separates malware families into distinct clusters\")\n",
        "            print(f\"â€¢ DBSCAN æœ‰æ•ˆåœ°å°‡æƒ¡æ„è»Ÿé«”å®¶æ—åˆ†é›¢æˆä¸åŒçš„ç¾¤é›†\")\n",
        "            print(f\"â€¢ Noise samples may represent unique variants or misclassified files\")\n",
        "            print(f\"â€¢ é›œè¨Šæ¨£æœ¬å¯èƒ½ä»£è¡¨ç¨ç‰¹è®Šç¨®æˆ–éŒ¯èª¤åˆ†é¡çš„æª”æ¡ˆ\")\n",
        "            print(f\"â€¢ eps=30 works well for malware family detection\")\n",
        "            print(f\"â€¢ eps=30 åœ¨æƒ¡æ„è»Ÿé«”å®¶æ—åµæ¸¬ä¸­æ•ˆæœè‰¯å¥½\")\n",
        "        \n",
        "        else:\n",
        "            print(\"âŒ DBSCAN clustering failed to produce results\")\n",
        "    \n",
        "    else:\n",
        "        print(\"âŒ No TLSH data available for clustering\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error in DBSCAN clustering: {e}\")\n",
        "    print(\"This may be due to insufficient data or library compatibility issues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hac-section",
      "metadata": {},
      "source": [
        "## Step 4: HAC-T Clustering for Malware Families / æ­¥é©Ÿ 4ï¼šç”¨æ–¼æƒ¡æ„è»Ÿé«”å®¶æ—çš„ HAC-T åˆ†ç¾¤\n",
        "\n",
        "### HAC-T: Hierarchical Agglomerative Clustering for TLSH / HAC-Tï¼šç”¨æ–¼ TLSH çš„éšå±¤å¼èšåˆåˆ†ç¾¤\n",
        "\n",
        "HAC-T is specifically designed for TLSH data and offers advantages for malware analysis:\n",
        "\n",
        "HAC-T å°ˆé–€ç‚º TLSH è³‡æ–™è¨­è¨ˆï¼Œåœ¨æƒ¡æ„è»Ÿé«”åˆ†æä¸­æä¾›å„ªå‹¢ï¼š\n",
        "\n",
        "- **Hierarchical structure**: Shows evolutionary relationships between malware variants\n",
        "- **éšå±¤çµæ§‹**: é¡¯ç¤ºæƒ¡æ„è»Ÿé«”è®Šç¨®é–“çš„æ¼”åŒ–é—œä¿‚\n",
        "- **Distance threshold**: Uses TLSH distance thresholds for family classification\n",
        "- **è·é›¢é–¾å€¼**: ä½¿ç”¨ TLSH è·é›¢é–¾å€¼é€²è¡Œå®¶æ—åˆ†é¡\n",
        "- **Deterministic**: Produces consistent results across runs\n",
        "- **ç¢ºå®šæ€§**: åœ¨å¤šæ¬¡é‹è¡Œä¸­ç”¢ç”Ÿä¸€è‡´çš„çµæœ\n",
        "\n",
        "### HAC-T Process / HAC-T æµç¨‹:\n",
        "1. **Build VP-Tree**: Efficient data structure for TLSH distance queries\n",
        "2. **å»ºç«‹ VP-Tree**: ç”¨æ–¼ TLSH è·é›¢æŸ¥è©¢çš„é«˜æ•ˆè³‡æ–™çµæ§‹\n",
        "3. **Agglomerative clustering**: Merge closest samples iteratively\n",
        "4. **èšåˆåˆ†ç¾¤**: è¿­ä»£åˆä½µæœ€è¿‘çš„æ¨£æœ¬\n",
        "5. **Distance threshold**: Stop merging when distance exceeds threshold\n",
        "6. **è·é›¢é–¾å€¼**: ç•¶è·é›¢è¶…éé–¾å€¼æ™‚åœæ­¢åˆä½µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hac-t-clustering",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply HAC-T clustering to malware data / å°æƒ¡æ„è»Ÿé«”è³‡æ–™æ‡‰ç”¨ HAC-T åˆ†ç¾¤\n",
        "print(\"ğŸŒ³ HAC-T Malware Clustering / HAC-T æƒ¡æ„è»Ÿé«”åˆ†ç¾¤\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    if 'tlist' in locals() and tlist is not None:\n",
        "        # Use smaller subset for HAC-T demonstration (it's computationally intensive)\n",
        "        # ç‚º HAC-T ç¤ºç¯„ä½¿ç”¨è¼ƒå°å­é›†ï¼ˆå®ƒåœ¨è¨ˆç®—ä¸Šå¾ˆå¯†é›†ï¼‰\n",
        "        hac_samples = min(200, len(tlist))  # Smaller subset for performance\n",
        "        \n",
        "        print(f\"ğŸ“Š Running HAC-T clustering on {hac_samples} samples...\")\n",
        "        print(f\"ğŸ“Š å° {hac_samples} å€‹æ¨£æœ¬é‹è¡Œ HAC-T åˆ†ç¾¤...\")\n",
        "        print(f\"â±ï¸ This may take a moment for distance calculations...\")\n",
        "        print(f\"â±ï¸ è·é›¢è¨ˆç®—å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“...\")\n",
        "        \n",
        "        # Create temporary file for HAC-T\n",
        "        temp_file = 'temp_hac_data.csv'\n",
        "        with open(temp_file, 'w') as f:\n",
        "            f.write('sha1_hash,tlsh,signature\\n')\n",
        "            for i in range(hac_samples):\n",
        "                sha1 = f\"sample_{i:06d}\"  # Dummy SHA1\n",
        "                tlsh_hash = tlist[i]\n",
        "                family = labels[0][i] if labels and len(labels[0]) > i else 'Unknown'\n",
        "                f.write(f\"{sha1},{tlsh_hash},{family}\\n\")\n",
        "        \n",
        "        # Run HAC-T clustering\n",
        "        hac_result = HAC_T_opt(temp_file, CDist=100, step3=0, outfname='temp_hac_out.txt', cenfname='temp_hac_cen.txt')\n",
        "        \n",
        "        if hac_result is not None:\n",
        "            # Analyze HAC-T results\n",
        "            unique_hac_labels = set(hac_result)\n",
        "            n_hac_clusters = len(unique_hac_labels)\n",
        "            \n",
        "            print(f\"\\nâœ… HAC-T Clustering Results / HAC-T åˆ†ç¾¤çµæœ:\")\n",
        "            print(f\"   Clusters formed / å½¢æˆçš„ç¾¤é›†æ•¸: {n_hac_clusters}\")\n",
        "            print(f\"   Processed samples / è™•ç†çš„æ¨£æœ¬æ•¸: {len(hac_result)}\")\n",
        "            print(f\"   Average cluster size / å¹³å‡ç¾¤é›†å¤§å°: {len(hac_result) / n_hac_clusters:.1f}\")\n",
        "            \n",
        "            # Compare HAC-T with known family labels\n",
        "            if labels and labels[0]:\n",
        "                print(f\"\\nğŸ” HAC-T vs Known Families Comparison / HAC-T vs å·²çŸ¥å®¶æ—æ¯”è¼ƒ:\")\n",
        "                \n",
        "                # Count cluster purity (samples with same family in same cluster)\n",
        "                cluster_purity = 0\n",
        "                total_comparisons = 0\n",
        "                \n",
        "                for cluster_id in unique_hac_labels:\n",
        "                    cluster_indices = [i for i, label in enumerate(hac_result) if label == cluster_id]\n",
        "                    if len(cluster_indices) > 1:\n",
        "                        cluster_families = [labels[0][i] for i in cluster_indices if i < len(labels[0])]\n",
        "                        if cluster_families:\n",
        "                            most_common_family = max(set(cluster_families), key=cluster_families.count)\n",
        "                            same_family_count = cluster_families.count(most_common_family)\n",
        "                            purity = same_family_count / len(cluster_families)\n",
        "                            \n",
        "                            if len(cluster_indices) <= 10:  # Show details for small clusters\n",
        "                                family_dist = {}\n",
        "                                for fam in cluster_families:\n",
        "                                    family_dist[fam] = family_dist.get(fam, 0) + 1\n",
        "                                print(f\"   Cluster {cluster_id}: {len(cluster_indices)} samples, purity: {purity:.2f}\")\n",
        "                                print(f\"      Families: {dict(family_dist)}\")\n",
        "                            \n",
        "                            cluster_purity += purity\n",
        "                            total_comparisons += 1\n",
        "                \n",
        "                if total_comparisons > 0:\n",
        "                    avg_purity = cluster_purity / total_comparisons\n",
        "                    print(f\"\\nğŸ“Š Overall Cluster Purity / æ•´é«”ç¾¤é›†ç´”åº¦: {avg_purity:.3f}\")\n",
        "                    print(f\"   (1.0 = perfect clustering, 0.0 = random clustering)\")\n",
        "                    print(f\"   (1.0 = å®Œç¾åˆ†ç¾¤ï¼Œ0.0 = éš¨æ©Ÿåˆ†ç¾¤)\")\n",
        "            \n",
        "            # Visualize HAC-T results\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            \n",
        "            # Plot cluster distribution\n",
        "            plt.subplot(1, 2, 1)\n",
        "            cluster_sizes = [list(hac_result).count(label) for label in unique_hac_labels]\n",
        "            plt.hist(cluster_sizes, bins=15, alpha=0.7, edgecolor='black')\n",
        "            plt.xlabel('Cluster Size / ç¾¤é›†å¤§å°')\n",
        "            plt.ylabel('Frequency / é »ç‡')\n",
        "            plt.title('HAC-T Cluster Size Distribution\\nHAC-T ç¾¤é›†å¤§å°åˆ†ä½ˆ')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Plot sample assignments\n",
        "            plt.subplot(1, 2, 2)\n",
        "            sample_indices = range(min(100, len(hac_result)))\n",
        "            sample_labels = hac_result[:len(sample_indices)]\n",
        "            colors = [plt.cm.tab20(x % 20) for x in sample_labels]\n",
        "            plt.scatter(sample_indices, sample_labels, c=colors, alpha=0.7)\n",
        "            plt.xlabel('Sample Index / æ¨£æœ¬ç´¢å¼•')\n",
        "            plt.ylabel('Cluster ID / ç¾¤é›† ID')\n",
        "            plt.title('HAC-T Cluster Assignments\\nHAC-T ç¾¤é›†åˆ†é…')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "        # Clean up temporary files\n",
        "        for temp_file_name in [temp_file, 'temp_hac_out.txt', 'temp_hac_cen.txt']:\n",
        "            if os.path.exists(temp_file_name):\n",
        "                os.remove(temp_file_name)\n",
        "        \n",
        "        print(\"\\nğŸ’¡ HAC-T Analysis Insights / HAC-T åˆ†ææ´å¯Ÿ:\")\n",
        "        print(f\"â€¢ HAC-T creates hierarchical clusters based on TLSH distances\")\n",
        "        print(f\"â€¢ HAC-T åŸºæ–¼ TLSH è·é›¢å‰µå»ºéšå±¤ç¾¤é›†\")\n",
        "        print(f\"â€¢ CDist=100 threshold works well for malware family separation\")\n",
        "        print(f\"â€¢ CDist=100 é–¾å€¼åœ¨æƒ¡æ„è»Ÿé«”å®¶æ—åˆ†é›¢ä¸­æ•ˆæœè‰¯å¥½\")\n",
        "        print(f\"â€¢ Higher purity indicates better family clustering\")\n",
        "        print(f\"â€¢ æ›´é«˜ç´”åº¦è¡¨ç¤ºæ›´å¥½çš„å®¶æ—åˆ†ç¾¤\")\n",
        "\n",
        "    else:\n",
        "        print(\"âŒ No TLSH data available for HAC-T clustering\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error in HAC-T clustering: {e}\")\n",
        "    print(\"This may be due to library compatibility or computational limitations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classification-section",
      "metadata": {},
      "source": [
        "## Step 5: Unknown Malware Classification / æ­¥é©Ÿ 5ï¼šæœªçŸ¥æƒ¡æ„è»Ÿé«”åˆ†é¡\n",
        "\n",
        "### Real-world Scenario: Classifying New Malware / çœŸå¯¦ä¸–ç•Œæƒ…å¢ƒï¼šåˆ†é¡æ–°æƒ¡æ„è»Ÿé«”\n",
        "\n",
        "In practice, analysts receive unknown malware samples and need to:\n",
        "\n",
        "åœ¨å¯¦è¸ä¸­ï¼Œåˆ†æå¸«æ”¶åˆ°æœªçŸ¥æƒ¡æ„è»Ÿé«”æ¨£æœ¬ä¸¦éœ€è¦ï¼š\n",
        "\n",
        "1. **Calculate TLSH** of the unknown sample / è¨ˆç®—æœªçŸ¥æ¨£æœ¬çš„ TLSH\n",
        "2. **Find similar samples** in the database / åœ¨è³‡æ–™åº«ä¸­æ‰¾åˆ°ç›¸ä¼¼æ¨£æœ¬\n",
        "3. **Classify based on similarity** / åŸºæ–¼ç›¸ä¼¼æ€§é€²è¡Œåˆ†é¡\n",
        "4. **Assess confidence** of the classification / è©•ä¼°åˆ†é¡çš„ç½®ä¿¡åº¦\n",
        "\n",
        "### Classification Strategy / åˆ†é¡ç­–ç•¥:\n",
        "- **Distance < 50**: High confidence - same variant / é«˜ç½®ä¿¡åº¦ - åŒä¸€è®Šç¨®\n",
        "- **Distance 50-100**: Medium confidence - same family / ä¸­ç­‰ç½®ä¿¡åº¦ - åŒä¸€å®¶æ—  \n",
        "- **Distance > 100**: Low confidence - possibly new family / ä½ç½®ä¿¡åº¦ - å¯èƒ½æ˜¯æ–°å®¶æ—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unknown-classification",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate unknown malware classification / æ¨¡æ“¬æœªçŸ¥æƒ¡æ„è»Ÿé«”åˆ†é¡\n",
        "print(\"ğŸ•µï¸ Unknown Malware Classification / æœªçŸ¥æƒ¡æ„è»Ÿé«”åˆ†é¡\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "try:\n",
        "    if 'tlist' in locals() and tlist is not None and len(tlist) > 10:\n",
        "        # Select a few samples to act as \"unknown\" samples\n",
        "        # é¸æ“‡ä¸€äº›æ¨£æœ¬ä½œç‚ºã€ŒæœªçŸ¥ã€æ¨£æœ¬\n",
        "        unknown_indices = [10, 50, 100] if len(tlist) > 100 else [5, 10, 15]\n",
        "        unknown_indices = [idx for idx in unknown_indices if idx < len(tlist)]\n",
        "        \n",
        "        print(f\"ğŸ¯ Classifying {len(unknown_indices)} unknown samples...\")\n",
        "        print(f\"ğŸ¯ åˆ†é¡ {len(unknown_indices)} å€‹æœªçŸ¥æ¨£æœ¬...\")\n",
        "        \n",
        "        # Import TLSH for distance calculations\n",
        "        import tlsh\n",
        "        \n",
        "        for i, unknown_idx in enumerate(unknown_indices):\n",
        "            if unknown_idx >= len(tlist):\n",
        "                continue\n",
        "                \n",
        "            unknown_tlsh = tlist[unknown_idx]\n",
        "            true_family = labels[0][unknown_idx] if labels and len(labels[0]) > unknown_idx else 'Unknown'\n",
        "            \n",
        "            print(f\"\\nğŸ“‹ Unknown Sample #{i+1} / æœªçŸ¥æ¨£æœ¬ #{i+1}:\")\n",
        "            print(f\"   TLSH: {unknown_tlsh[:40]}...\")\n",
        "            print(f\"   True family (hidden from classifier): {true_family}\")\n",
        "            print(f\"   çœŸå¯¦å®¶æ—ï¼ˆå°åˆ†é¡å™¨éš±è—ï¼‰ï¼š{true_family}\")\n",
        "            \n",
        "            # Find similar samples\n",
        "            try:\n",
        "                unknown_obj = tlsh.Tlsh()\n",
        "                unknown_obj.fromTlshStr(unknown_tlsh)\n",
        "                \n",
        "                similarities = []\n",
        "                # Compare with a sample of known malware (excluding the unknown sample itself)\n",
        "                comparison_samples = min(200, len(tlist))\n",
        "                \n",
        "                for j in range(comparison_samples):\n",
        "                    if j == unknown_idx:\n",
        "                        continue  # Skip self\n",
        "                        \n",
        "                    try:\n",
        "                        known_obj = tlsh.Tlsh()\n",
        "                        known_obj.fromTlshStr(tlist[j])\n",
        "                        distance = unknown_obj.diff(known_obj)\n",
        "                        \n",
        "                        if distance != -1:  # Valid comparison\n",
        "                            known_family = labels[0][j] if labels and len(labels[0]) > j else 'Unknown'\n",
        "                            similarities.append((distance, known_family, j))\n",
        "                            \n",
        "                    except Exception:\n",
        "                        continue\n",
        "                \n",
        "                # Sort by distance (closest first)\n",
        "                similarities.sort(key=lambda x: x[0])\n",
        "                \n",
        "                if similarities:\n",
        "                    print(f\"\\n   ğŸ” Top 5 Most Similar Samples / å‰ 5 å€‹æœ€ç›¸ä¼¼æ¨£æœ¬:\")\n",
        "                    \n",
        "                    for rank, (distance, family, sample_idx) in enumerate(similarities[:5], 1):\n",
        "                        confidence = \"HIGH\" if distance <= 50 else \"MEDIUM\" if distance <= 100 else \"LOW\"\n",
        "                        confidence_cn = \"é«˜\" if distance <= 50 else \"ä¸­\" if distance <= 100 else \"ä½\"\n",
        "                        print(f\"   {rank}. Distance: {distance:3d} | Family: {family:12} | Confidence: {confidence}/{confidence_cn}\")\n",
        "                    \n",
        "                    # Make classification based on closest samples\n",
        "                    closest_distance = similarities[0][0]\n",
        "                    closest_family = similarities[0][1]\n",
        "                    \n",
        "                    # Vote from top 3 closest samples\n",
        "                    top_families = [sim[1] for sim in similarities[:3] if sim[0] <= 100]\n",
        "                    if top_families:\n",
        "                        family_votes = {}\n",
        "                        for fam in top_families:\n",
        "                            family_votes[fam] = family_votes.get(fam, 0) + 1\n",
        "                        predicted_family = max(family_votes.keys(), key=lambda x: family_votes[x])\n",
        "                        vote_confidence = family_votes[predicted_family] / len(top_families)\n",
        "                    else:\n",
        "                        predicted_family = \"Unknown/New Family\"\n",
        "                        vote_confidence = 0.0\n",
        "                    \n",
        "                    print(f\"\\n   ğŸ¯ Classification Result / åˆ†é¡çµæœ:\")\n",
        "                    print(f\"      Predicted family / é æ¸¬å®¶æ—: {predicted_family}\")\n",
        "                    print(f\"      Closest distance / æœ€è¿‘è·é›¢: {closest_distance}\")\n",
        "                    print(f\"      Vote confidence / æŠ•ç¥¨ç½®ä¿¡åº¦: {vote_confidence:.2f}\")\n",
        "                    \n",
        "                    # Check if classification is correct\n",
        "                    correct = predicted_family == true_family\n",
        "                    result_icon = \"âœ…\" if correct else \"âŒ\"\n",
        "                    print(f\"      Accuracy / æº–ç¢ºæ€§: {result_icon} {'Correct' if correct else 'Incorrect'}\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   âŒ No similar samples found\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   âŒ Error processing sample: {e}\")\n",
        "        \n",
        "        print(\"\\nğŸ’¡ Classification Process Insights / åˆ†é¡æµç¨‹æ´å¯Ÿ:\")\n",
        "        print(\"â€¢ Distance-based classification works well for malware families\")\n",
        "        print(\"â€¢ åŸºæ–¼è·é›¢çš„åˆ†é¡åœ¨æƒ¡æ„è»Ÿé«”å®¶æ—ä¸­æ•ˆæœè‰¯å¥½\")\n",
        "        print(\"â€¢ Voting from multiple similar samples increases accuracy\")\n",
        "        print(\"â€¢ å¾å¤šå€‹ç›¸ä¼¼æ¨£æœ¬æŠ•ç¥¨æé«˜æº–ç¢ºæ€§\")\n",
        "        print(\"â€¢ Very high distances (>150) may indicate new malware families\")\n",
        "        print(\"â€¢ éå¸¸é«˜çš„è·é›¢ (>150) å¯èƒ½è¡¨ç¤ºæ–°çš„æƒ¡æ„è»Ÿé«”å®¶æ—\")\n",
        "    \n",
        "    else:\n",
        "        print(\"âŒ Insufficient data for classification demonstration\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error in classification: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-section",
      "metadata": {},
      "source": [
        "## Summary and Practical Applications / ç¸½çµå’Œå¯¦éš›æ‡‰ç”¨\n",
        "\n",
        "### What We Accomplished / æˆ‘å€‘å®Œæˆçš„å…§å®¹:\n",
        "\n",
        "1. **Real Data Analysis / çœŸå¯¦è³‡æ–™åˆ†æ**\n",
        "   - Loaded and explored actual malware samples with TLSH hashes\n",
        "   - è¼‰å…¥å’Œæ¢ç´¢å…·æœ‰ TLSH é›œæ¹Šçš„å¯¦éš›æƒ¡æ„è»Ÿé«”æ¨£æœ¬\n",
        "   - Analyzed family distributions and data quality\n",
        "   - åˆ†æå®¶æ—åˆ†ä½ˆå’Œè³‡æ–™å“è³ª\n",
        "\n",
        "2. **Distance Analysis / è·é›¢åˆ†æ**\n",
        "   - Calculated TLSH distances between malware samples\n",
        "   - è¨ˆç®—æƒ¡æ„è»Ÿé«”æ¨£æœ¬é–“çš„ TLSH è·é›¢\n",
        "   - Established distance thresholds for family classification\n",
        "   - å»ºç«‹å®¶æ—åˆ†é¡çš„è·é›¢é–¾å€¼\n",
        "\n",
        "3. **Clustering Implementation / åˆ†ç¾¤å¯¦ä½œ**\n",
        "   - Applied DBSCAN for density-based malware clustering\n",
        "   - æ‡‰ç”¨ DBSCAN é€²è¡ŒåŸºæ–¼å¯†åº¦çš„æƒ¡æ„è»Ÿé«”åˆ†ç¾¤\n",
        "   - Implemented HAC-T for hierarchical TLSH clustering\n",
        "   - å¯¦ä½œ HAC-T é€²è¡Œéšå±¤å¼ TLSH åˆ†ç¾¤\n",
        "\n",
        "4. **Practical Classification / å¯¦ç”¨åˆ†é¡**\n",
        "   - Demonstrated unknown sample classification workflow\n",
        "   - ç¤ºç¯„æœªçŸ¥æ¨£æœ¬åˆ†é¡å·¥ä½œæµç¨‹\n",
        "   - Used distance-based voting for family prediction\n",
        "   - ä½¿ç”¨åŸºæ–¼è·é›¢çš„æŠ•ç¥¨é€²è¡Œå®¶æ—é æ¸¬\n",
        "\n",
        "### Production Applications / ç”Ÿç”¢æ‡‰ç”¨:\n",
        "\n",
        "- **ğŸš¨ Incident Response**: Quickly classify unknown malware during security incidents\n",
        "- **ğŸ” Threat Hunting**: Identify related malware campaigns and attack patterns\n",
        "- **ğŸ“Š Threat Intelligence**: Generate family-based IOCs and detection signatures\n",
        "- **ğŸ¤– Automated Analysis**: Integrate into malware analysis pipelines\n",
        "- **ğŸ“ˆ Campaign Tracking**: Track malware evolution and variant development\n",
        "\n",
        "### Best Practices / æœ€ä½³å¯¦è¸:\n",
        "\n",
        "1. **Parameter Tuning / åƒæ•¸èª¿æ•´**\n",
        "   - DBSCAN: eps=30, min_samples=2 for malware families\n",
        "   - HAC-T: CDist=100 for family-level clustering\n",
        "   - Classification: Distance thresholds 50/100 for confidence levels\n",
        "\n",
        "2. **Data Quality / è³‡æ–™å“è³ª**\n",
        "   - Validate TLSH hash format before clustering\n",
        "   - Handle missing or corrupted hashes appropriately\n",
        "   - Maintain clean family labels for validation\n",
        "\n",
        "3. **Scalability / å¯æ“´å±•æ€§**\n",
        "   - Use VP-Tree or similar structures for large datasets\n",
        "   - Implement incremental clustering for real-time analysis\n",
        "   - Consider distributed processing for enterprise scale\n",
        "\n",
        "### Next Steps / ä¸‹ä¸€æ­¥:\n",
        "\n",
        "- **Integrate with SIEM platforms** for automated threat detection\n",
        "- **èˆ‡ SIEM å¹³å°æ•´åˆ**ç”¨æ–¼è‡ªå‹•å¨è„…åµæ¸¬\n",
        "- **Develop custom distance thresholds** for your specific malware types\n",
        "- **é–‹ç™¼è‡ªå®šç¾©è·é›¢é–¾å€¼**é©ç”¨æ–¼æ‚¨ç‰¹å®šçš„æƒ¡æ„è»Ÿé«”é¡å‹\n",
        "- **Implement real-time classification** for file upload systems\n",
        "- **å¯¦ä½œå³æ™‚åˆ†é¡**ç”¨æ–¼æª”æ¡ˆä¸Šå‚³ç³»çµ±\n",
        "- **Build family evolution tracking** for advanced threat intelligence\n",
        "- **å»ºç«‹å®¶æ—æ¼”åŒ–è¿½è¹¤**ç”¨æ–¼é€²éšå¨è„…æƒ…å ±\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ Congratulations! / æ­å–œï¼\n",
        "\n",
        "You have successfully completed a comprehensive TLSH malware analysis tutorial using real malware data. You now have practical skills for:\n",
        "\n",
        "æ‚¨å·²æˆåŠŸå®Œæˆä½¿ç”¨çœŸå¯¦æƒ¡æ„è»Ÿé«”è³‡æ–™çš„ç¶œåˆ TLSH æƒ¡æ„è»Ÿé«”åˆ†ææ•™å­¸ã€‚æ‚¨ç¾åœ¨å…·å‚™ä»¥ä¸‹å¯¦ç”¨æŠ€èƒ½ï¼š\n",
        "\n",
        "- **âœ… Raw malware data analysis and preprocessing**\n",
        "- **âœ… TLSH-based similarity analysis and clustering**  \n",
        "- **âœ… Unknown malware classification and family prediction**\n",
        "- **âœ… Production-ready malware analysis workflows**\n",
        "\n",
        "These skills are directly applicable to threat intelligence, incident response, and malware research roles in cybersecurity.\n",
        "\n",
        "é€™äº›æŠ€èƒ½å¯ç›´æ¥æ‡‰ç”¨æ–¼ç¶²è·¯å®‰å…¨é ˜åŸŸçš„å¨è„…æƒ…å ±ã€äº‹ä»¶éŸ¿æ‡‰å’Œæƒ¡æ„è»Ÿé«”ç ”ç©¶è§’è‰²ã€‚"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}